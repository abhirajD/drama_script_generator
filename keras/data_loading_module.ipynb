{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Concat Datafiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Format IP and OP for Network\n",
    "\n",
    "Heres a small cheat: If I say 'Hello' the network should say something like 'World'.. i.e the network has to learn to understand 'World','My name is' usually accompanies 'Hello'.\n",
    "\n",
    "#### Problem Break down\n",
    "Because we have multiple memory cells in LSTM, we can make the network complete larger segments of text, sentences may be. Our network is gonna take numeric data, we can have vectors helping us map chars in numeric format. Thus Vectorization shall we use. This gives us two optins to represent our text, lets talk about them and their pro-cons.\n",
    "    1. N-gram:\n",
    "        We create a vocabulary of words. Each sentence, or a chunk of text will be represented by these vectors composed of word unit vectors.\n",
    "    \n",
    "    2. N-char:\n",
    "        We create a vocabulary of chars i.e A,B,C,D....x,y,z and symbols etc. Each sentence, or a chunk of text will be represented by these huge vectors composed of char unit vectors.\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data(data_dir, seq_length):\n",
    "    data = open(data_dir, 'r').read()\n",
    "    chars = list(set(data))\n",
    "    VOCAB_SIZE = len(chars)\n",
    "\n",
    "    print('Data length: {} characters'.format(len(data)))\n",
    "    print('Vocabulary size: {} characters'.format(VOCAB_SIZE))\n",
    "\n",
    "    ix_to_char = {ix:char for ix, char in enumerate(chars)}\n",
    "    char_to_ix = {char:ix for ix, char in enumerate(chars)}\n",
    "\n",
    "    X = np.zeros((len(data)/seq_length, seq_length, VOCAB_SIZE))\n",
    "    y = np.zeros((len(data)/seq_length, seq_length, VOCAB_SIZE))\n",
    "    for i in range(0, len(data)/seq_length):\n",
    "        X_sequence = data[i*seq_length:(i+1)*seq_length]\n",
    "        X_sequence_ix = [char_to_ix[value] for value in X_sequence]\n",
    "        input_sequence = np.zeros((seq_length, VOCAB_SIZE))\n",
    "        \n",
    "        #Transpose: Feeding Character by Character\n",
    "        for j in range(seq_length):\n",
    "            input_sequence[j][X_sequence_ix[j]] = 1.\n",
    "            X[i] = input_sequence\n",
    "\n",
    "        y_sequence = data[i*seq_length+1:(i+1)*seq_length+1]\n",
    "        y_sequence_ix = [char_to_ix[value] for value in y_sequence]\n",
    "        target_sequence = np.zeros((seq_length, VOCAB_SIZE))\n",
    "        for j in range(seq_length):\n",
    "            target_sequence[j][y_sequence_ix[j]] = 1.\n",
    "            y[i] = target_sequence\n",
    "    return X, y, VOCAB_SIZE, ix_to_char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "seq_length = 50\n",
    "content_file = '../dataset/srt_content/01-Pilot.720pHDTV.en.content'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(content_file,'r', encoding='utf-8') as f:\n",
    "  data = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data length: 31695 characters\n",
      "Vocabulary size: 80 characters\n"
     ]
    }
   ],
   "source": [
    "chars = list(set(data))\n",
    "VOCAB_SIZE = len(chars)\n",
    "\n",
    "print('Data length: {} characters'.format(len(data)))\n",
    "print('Vocabulary size: {} characters'.format(VOCAB_SIZE))\n",
    "\n",
    "ix_to_char = {ix:char for ix, char in enumerate(chars)}\n",
    "char_to_ix = {char:ix for ix, char in enumerate(chars)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Define Zeros\n",
    "X = np.zeros((int(len(data)/seq_length), seq_length, VOCAB_SIZE))\n",
    "y = np.zeros((int(len(data)/seq_length), seq_length, VOCAB_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "♪ ♪(shatter echoing)(gasping, crying)(woman scream\n",
      "[66, 7, 66, 65, 36, 20, 70, 77, 77, 44, 42, 7, 44, 58, 20, 48, 76, 16, 74, 78, 65, 74, 70, 36, 51, 76, 16, 74, 29, 7, 58, 42, 15, 76, 16, 74, 78, 65, 3, 48, 6, 70, 16, 7, 36, 58, 42, 44, 70, 6]\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "X_sequence = data[i*seq_length:(i+1)*seq_length]\n",
    "X_sequence_ix = [char_to_ix[value] for value in X_sequence]\n",
    "print(X_sequence)\n",
    "print(X_sequence_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "  ..., \n",
      "  [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...,  0.  0.  0.]]\n",
      "\n",
      " [[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "  ..., \n",
      "  [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...,  0.  0.  0.]]\n",
      "\n",
      " [[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "  ..., \n",
      "  [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...,  0.  0.  0.]]\n",
      "\n",
      " ..., \n",
      " [[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "  ..., \n",
      "  [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...,  0.  0.  0.]]\n",
      "\n",
      " [[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "  ..., \n",
      "  [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...,  0.  0.  0.]]\n",
      "\n",
      " [[ 0.  0.  0. ...,  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "  ..., \n",
      "  [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...,  0.  0.  0.]\n",
      "  [ 0.  0.  0. ...,  0.  0.  0.]]]\n"
     ]
    }
   ],
   "source": [
    "input_sequence = np.zeros((seq_length, VOCAB_SIZE))\n",
    "for j in range(seq_length):\n",
    "    input_sequence[j][X_sequence_ix[j]] = 1.\n",
    "    X[i] = input_sequence\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ♪(shatter echoing)(gasping, crying)(woman screami\n",
      "[7, 66, 65, 36, 20, 70, 77, 77, 44, 42, 7, 44, 58, 20, 48, 76, 16, 74, 78, 65, 74, 70, 36, 51, 76, 16, 74, 29, 7, 58, 42, 15, 76, 16, 74, 78, 65, 3, 48, 6, 70, 16, 7, 36, 58, 42, 44, 70, 6, 76]\n"
     ]
    }
   ],
   "source": [
    "y_sequence = data[i*seq_length+1:(i+1)*seq_length+1]\n",
    "y_sequence_ix = [char_to_ix[value] for value in y_sequence]\n",
    "print(y_sequence)\n",
    "print(y_sequence_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_sequence = np.zeros((seq_length, VOCAB_SIZE))\n",
    "for i in range(seq_length):\n",
    "  target_sequence[j][y_sequence_ix[i]] = 1\n",
    "  y[i] = target_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
